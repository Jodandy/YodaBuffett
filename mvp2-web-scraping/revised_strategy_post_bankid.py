#!/usr/bin/env python3

"""
Revised Strategy - Post BankID Discovery
Back to hybrid approach with focus on public sources
"""

from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime


@dataclass 
class DataSource:
    name: str
    url: str
    coverage: str  # 'complete', 'partial', 'major_companies'
    legal_status: str  # 'safe', 'gray_zone', 'risky'
    automation: str  # 'easy', 'medium', 'hard', 'impossible'
    cost: str  # 'free', 'cheap', 'expensive'
    data_quality: str  # 'high', 'medium', 'low'
    notes: str = ""


class RevisedSwedishDataStrategy:
    """
    Post-BankID reality check - focus on actually accessible sources
    """
    
    def __init__(self):
        self.data_sources = [
            DataSource(
                "B√∂rskollen News", 
                "https://www.borskollen.se/nyheter/27/",
                "complete", "gray_zone", "easy", "free", "high",
                "robots.txt allows /nyheter/27* - daily report summaries"
            ),
            
            DataSource(
                "Company RSS Feeds",
                "Various company investor pages", 
                "partial", "safe", "easy", "free", "high",
                "Volvo confirmed working, need to find others"
            ),
            
            DataSource(
                "Email Newsletters",
                "Company investor relations subscriptions",
                "partial", "safe", "medium", "free", "high", 
                "Manual setup, email parsing pipeline needed"
            ),
            
            DataSource(
                "Bolagsverket Open Data",
                "https://bolagsverket.se/ff/foretagsfakta/",
                "complete", "safe", "medium", "free", "medium",
                "Basic company info, may have annual reports"
            ),
            
            DataSource(
                "AllaBolags.se", 
                "https://www.allabolag.se/",
                "complete", "gray_zone", "hard", "free", "medium",
                "Comprehensive but may have anti-scraping"
            ),
            
            DataSource(
                "Nasdaq Stockholm",
                "https://www.nasdaqomxnordic.com/", 
                "major_companies", "gray_zone", "medium", "free", "high",
                "Official exchange data, limited to listed companies"
            ),
            
            DataSource(
                "Manual Collection",
                "Direct company IR pages",
                "targeted", "safe", "impossible", "free", "high",
                "100% safe fallback, ~2 hours/month for key companies"
            )
        ]
    
    def rank_sources_by_feasibility(self) -> List[DataSource]:
        """Rank data sources by implementation feasibility"""
        
        def feasibility_score(source: DataSource) -> int:
            legal_scores = {"safe": 3, "gray_zone": 1, "risky": -2}
            automation_scores = {"easy": 3, "medium": 2, "hard": 1, "impossible": 0}
            coverage_scores = {"complete": 3, "partial": 2, "major_companies": 2, "targeted": 1}
            
            return (legal_scores.get(source.legal_status, 0) + 
                   automation_scores.get(source.automation, 0) +
                   coverage_scores.get(source.coverage, 0))
        
        return sorted(self.data_sources, key=feasibility_score, reverse=True)
    
    def generate_implementation_roadmap(self) -> str:
        """Generate realistic implementation roadmap"""
        
        ranked_sources = self.rank_sources_by_feasibility()
        
        roadmap = f"""
üó∫Ô∏è REVISED IMPLEMENTATION ROADMAP
Post-BankID Reality Check
{'='*50}

üìÖ WEEK 1-2: Safe Foundation
‚úÖ RSS Feeds (Proven)
- Expand Volvo RSS success to other companies
- Build RSS monitoring system
- 30% automation coverage

‚úÖ Email Subscriptions (Manual Setup)  
- Subscribe to 20 major company newsletters
- Build email parsing pipeline
- +20% coverage boost

üìÖ WEEK 3-4: Gray Zone Testing
üü° B√∂rskollen News (/nyheter/27*)
- Test robots.txt compliance approach
- Daily report summaries scraping
- Could add 40% coverage

üü° Bolagsverket Open Data
- Investigate public API availability
- Annual reports collection
- Government data = safer

üìÖ MONTH 2: Advanced Sources  
üü° Nasdaq Stockholm
- Official exchange feeds
- Major companies only but high quality
- Test anti-bot measures

üü° AllaBolags.se (If needed)
- Last resort for complete coverage
- Heavy anti-scraping expected
- Use very conservative approach

üìÖ MONTH 3: Polish & Scale
‚úÖ Manual Fallback Process
- 2 hours/month manual collection
- Focus on key companies missed by automation
- 100% safe backup strategy

üéØ EXPECTED FINAL COVERAGE:
- RSS Feeds: 30% (high confidence dates)
- Email Newsletters: 20% (medium confidence) 
- B√∂rskollen: 40% (daily discovery)
- Manual: 10% (key companies backup)
- Total: ~85% automated, 15% manual

‚è±Ô∏è TIME INVESTMENT:
- Setup: 2 weeks initial development
- Daily: 5 minutes automated monitoring  
- Weekly: 15 minutes manual verification
- Monthly: 2 hours manual collection
- Annual: ~30 hours total

üí∞ COST: $0 (all free sources)
‚öñÔ∏è LEGAL RISK: Minimal (mostly safe sources)
üìä COVERAGE: ~85% of Swedish market
"""
        
        return roadmap
    
    def create_source_analysis_table(self) -> str:
        """Create detailed source analysis"""
        
        ranked = self.rank_sources_by_feasibility()
        
        table = f"""
üìä DATA SOURCE ANALYSIS
{'='*80}
{'Source':<20} {'Coverage':<12} {'Legal':<10} {'Auto':<8} {'Quality':<8} {'Score':<6}
{'-'*80}
"""
        
        for source in ranked:
            legal_scores = {"safe": 3, "gray_zone": 1, "risky": -2}
            automation_scores = {"easy": 3, "medium": 2, "hard": 1, "impossible": 0}
            coverage_scores = {"complete": 3, "partial": 2, "major_companies": 2, "targeted": 1}
            
            score = (legal_scores.get(source.legal_status, 0) + 
                    automation_scores.get(source.automation, 0) +
                    coverage_scores.get(source.coverage, 0))
            
            table += f"{source.name:<20} {source.coverage:<12} {source.legal_status:<10} {source.automation:<8} {source.data_quality:<8} {score:<6}\n"
            
        table += f"\nüí° Recommendation: Focus on sources with score ‚â• 4"
        
        return table
    
    def calculate_realistic_workload(self) -> Dict[str, any]:
        """Calculate realistic workload without BankID access"""
        
        # Swedish market breakdown
        large_cap = 30      # OMX Stockholm 30
        mid_cap = 50        # Mid & Small Cap
        spotlight = 200     # Spotlight companies
        unlisted_major = 50 # Major unlisted companies
        
        # Coverage estimates
        rss_coverage = int(large_cap * 0.4)  # 40% have useful RSS
        email_coverage = int(large_cap * 0.6) # 60% have newsletters
        automated_coverage = rss_coverage + email_coverage
        manual_coverage = large_cap - automated_coverage + 20  # +20 key mid-cap
        
        return {
            'total_companies_tracked': large_cap + 20,  # Focus on most important
            'automated_companies': automated_coverage,
            'manual_companies': manual_coverage,
            'automation_percentage': int(automated_coverage / (large_cap + 20) * 100),
            
            'weekly_time_minutes': 20,  # 15 min monitoring + 5 min manual
            'monthly_time_hours': 3,    # 2 hours manual + 1 hour maintenance  
            'annual_time_hours': 36,    # Very reasonable
            
            'legal_risk': 'Minimal',
            'cost': 'Free',
            'coverage_quality': 'High for major companies'
        }


def main():
    """Present revised strategy post-BankID discovery"""
    
    strategy = RevisedSwedishDataStrategy()
    
    print("üèõÔ∏è FINANSINSPEKTIONEN REQUIRES BANKID")
    print("‚ùå Not suitable for automation")
    print("‚úÖ Back to hybrid public data approach\n")
    
    # Show source analysis
    source_table = strategy.create_source_analysis_table()
    print(source_table)
    
    # Show implementation roadmap
    roadmap = strategy.generate_implementation_roadmap()
    print(f"\n{roadmap}")
    
    # Show realistic workload
    workload = strategy.calculate_realistic_workload()
    print(f"\nüìä REALISTIC WORKLOAD ANALYSIS")
    print("="*40)
    print(f"Companies tracked: {workload['total_companies_tracked']}")
    print(f"Automated: {workload['automated_companies']} ({workload['automation_percentage']}%)")
    print(f"Manual: {workload['manual_companies']}")
    print(f"Weekly time: {workload['weekly_time_minutes']} minutes")
    print(f"Annual time: {workload['annual_time_hours']} hours")
    print(f"Legal risk: {workload['legal_risk']}")
    print(f"Cost: {workload['cost']}")
    
    print(f"\nüéØ BOTTOM LINE:")
    print(f"Still totally achievable! Focus on public sources.")
    print(f"3 hours/month for 85% automated Swedish market coverage.")


if __name__ == "__main__":
    main()